{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVBxXkQLmonw",
        "outputId": "00782454-cd43-41b0-d064-69c05a6ef074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.15.0\n",
            "Uninstalling tensorflow-2.15.0:\n",
            "  Successfully uninstalled tensorflow-2.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DICX78fdqlzi",
        "outputId": "0224a98a-40d5-4c50-89c6-e6cb289171ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bvr7J6jRvVKn",
        "outputId": "9aec32e4-2131-45d3-9909-d74e3ff343ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-cpu\n",
            "  Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.68.1)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow-cpu)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.5.0 (from tensorflow-cpu)\n",
            "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (3.12.1)\n",
            "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-cpu)\n",
            "  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow-cpu) (13.9.4)\n",
            "Collecting namex (from keras>=3.5.0->tensorflow-cpu)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
            "Collecting optree (from keras>=3.5.0->tensorflow-cpu)\n",
            "  Downloading optree-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-cpu) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-cpu) (0.1.2)\n",
            "Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (230.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.0/230.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Downloading optree-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.3/381.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: namex, optree, ml-dtypes, tensorboard, keras, tensorflow-cpu\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "Successfully installed keras-3.7.0 ml-dtypes-0.4.1 namex-0.0.8 optree-0.13.1 tensorboard-2.18.0 tensorflow-cpu-2.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDyzchcZvXoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece80321-fa11-44c0-bbd9-c926ee5b29b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          id  \\\n",
            "0  eS8QaBYoDU0_1-9-rgb_front   \n",
            "1  b9nWwzf0C5E_9-5-rgb_front   \n",
            "2  -fyFTnt9w9Q_4-5-rgb_front   \n",
            "3  f8ShD9YwEfo_5-2-rgb_front   \n",
            "4  5Oq-F-EC_pU_9-8-rgb_front   \n",
            "\n",
            "                                         translation  \\\n",
            "0  When the ball is picked up by your defender, w...   \n",
            "1  Now, from this position pick up your foot and ...   \n",
            "2                So just think of your backhand now.   \n",
            "3  But what it'll do is it'll bring up a window o...   \n",
            "4                            They also fold back up.   \n",
            "\n",
            "                                         numpy_array  \n",
            "0  [[0.0, 0.0054244995, 0.010101318, 0.034423828,...  \n",
            "1  [[0.0, 0.00022244453, 0.24072266, 0.0, 0.02577...  \n",
            "2  [[0.030654907, 0.020111084, 0.03955078, 0.1687...  \n",
            "3  [[0.056274414, 0.0, 0.0, 0.068237305, 0.0, 0.3...  \n",
            "4  [[0.0, 0.14453125, 0.0, 0.3569336, 0.004905700...  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# Define paths\n",
        "data_path = \"/content/drive/MyDrive/train/home/usuaris/imatge/ltarres/wicv2023/how2sign/i3d_features/train\"\n",
        "translation_file_path = \"/content/drive/MyDrive/id_translation_subset.pkl\"\n",
        "\n",
        "# Load the translations from the .pkl file\n",
        "with open(translation_file_path, 'rb') as file:\n",
        "    translation_data = pickle.load(file)\n",
        "\n",
        "# Convert translation data to a DataFrame\n",
        "translation_df = pd.DataFrame(translation_data)\n",
        "\n",
        "# Get the list of files in the directory and select the first 20 files\n",
        "file_list = os.listdir(data_path)[:]\n",
        "\n",
        "\n",
        "translations = []\n",
        "numpy_arrays = []\n",
        "ids = []\n",
        "\n",
        "# Process the first 100 files\n",
        "for npy_file in file_list:\n",
        "\n",
        "    file_id = npy_file.replace('.npy', '')\n",
        "\n",
        "\n",
        "    if file_id in translation_df['id'].values:\n",
        "        # Get the corresponding translation\n",
        "        translation = translation_df.loc[translation_df['id'] == file_id, 'translation'].values[0]\n",
        "\n",
        "        # Load the .npy file\n",
        "        npy_filepath = os.path.join(data_path, npy_file)\n",
        "        numpy_array = np.load(npy_filepath)\n",
        "\n",
        "        # Append to lists\n",
        "        translations.append(translation)\n",
        "        numpy_arrays.append(numpy_array)\n",
        "        ids.append(file_id)\n",
        "\n",
        "# Create a new DataFrame for the results\n",
        "results_df = pd.DataFrame({\n",
        "    'id': ids,\n",
        "    'translation': translations,\n",
        "    'numpy_array': numpy_arrays\n",
        "})\n",
        "\n",
        "# Display the new DataFrame\n",
        "print(results_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUEGGlLzvdGT",
        "outputId": "52517657-b89f-452c-f185-f8f2bf05ca68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30384, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "results_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAUeYIvrwLNJ"
      },
      "outputs": [],
      "source": [
        "def analyze_sequence_lengths(results_df):\n",
        "    # Calculate sequence lengths for each entry\n",
        "    sequence_lengths = [arr.shape[0] for arr in results_df['numpy_array']]\n",
        "\n",
        "    # Create a distribution analysis\n",
        "    length_stats = {\n",
        "        'min': np.min(sequence_lengths),\n",
        "        'max': np.max(sequence_lengths),\n",
        "        'mean': np.mean(sequence_lengths),\n",
        "        'median': np.median(sequence_lengths),\n",
        "        'std': np.std(sequence_lengths)\n",
        "    }\n",
        "\n",
        "    return sequence_lengths, length_stats\n",
        "\n",
        "def filter_short_sequences(results_df, max_length_threshold=300):\n",
        "    # Get original sequence lengths\n",
        "    sequence_lengths = [arr.shape[0] for arr in results_df['numpy_array']]\n",
        "\n",
        "    # Create mask for short sequences\n",
        "    short_sequence_mask = [length <= max_length_threshold for length in sequence_lengths]\n",
        "\n",
        "    # Filter dataframe\n",
        "    filtered_df = results_df[short_sequence_mask].copy()\n",
        "\n",
        "    # Print statistics\n",
        "    print(f\"Original dataset size: {len(results_df)}\")\n",
        "    print(f\"Filtered dataset size: {len(filtered_df)}\")\n",
        "    print(f\"Kept {len(filtered_df)/len(results_df)*100:.2f}% of the data\")\n",
        "\n",
        "    return filtered_df\n",
        "\n",
        "def analyze_translation_lengths(filtered_df):\n",
        "    # Analyze word counts in translations\n",
        "    word_counts = [len(text.split()) for text in filtered_df['translation']]\n",
        "\n",
        "    return {\n",
        "        'min_words': min(word_counts),\n",
        "        'max_words': max(word_counts),\n",
        "        'avg_words': np.mean(word_counts),\n",
        "        'median_words': np.median(word_counts)\n",
        "    }\n",
        "\n",
        "# Implementation\n",
        "def prepare_filtered_dataset():\n",
        "    # 1. First analyze the data\n",
        "    lengths, stats = analyze_sequence_lengths(results_df)\n",
        "    print(\"Original sequence statistics:\", stats)\n",
        "\n",
        "    # 2. Filter short sequences\n",
        "    filtered_df = filter_short_sequences(results_df, max_length_threshold=1000)\n",
        "\n",
        "    # 3. Analyze translation complexity\n",
        "    translation_stats = analyze_translation_lengths(filtered_df)\n",
        "    print(\"Translation statistics:\", translation_stats)\n",
        "\n",
        "    return filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s__ZRt-awN05",
        "outputId": "600e7271-c6c6-4b9d-ace8-45cfc6ddf5ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([372,\n",
              "  114,\n",
              "  37,\n",
              "  80,\n",
              "  71,\n",
              "  212,\n",
              "  499,\n",
              "  107,\n",
              "  50,\n",
              "  187,\n",
              "  152,\n",
              "  594,\n",
              "  110,\n",
              "  149,\n",
              "  99,\n",
              "  286,\n",
              "  126,\n",
              "  144,\n",
              "  36,\n",
              "  265,\n",
              "  274,\n",
              "  115,\n",
              "  110,\n",
              "  304,\n",
              "  81,\n",
              "  107,\n",
              "  246,\n",
              "  358,\n",
              "  83,\n",
              "  90,\n",
              "  142,\n",
              "  131,\n",
              "  132,\n",
              "  107,\n",
              "  117,\n",
              "  113,\n",
              "  47,\n",
              "  193,\n",
              "  153,\n",
              "  155,\n",
              "  277,\n",
              "  45,\n",
              "  57,\n",
              "  326,\n",
              "  27,\n",
              "  154,\n",
              "  241,\n",
              "  56,\n",
              "  33,\n",
              "  58,\n",
              "  365,\n",
              "  48,\n",
              "  132,\n",
              "  25,\n",
              "  120,\n",
              "  52,\n",
              "  79,\n",
              "  94,\n",
              "  225,\n",
              "  202,\n",
              "  367,\n",
              "  454,\n",
              "  180,\n",
              "  531,\n",
              "  232,\n",
              "  311,\n",
              "  179,\n",
              "  399,\n",
              "  448,\n",
              "  32,\n",
              "  41,\n",
              "  33,\n",
              "  101,\n",
              "  50,\n",
              "  168,\n",
              "  145,\n",
              "  380,\n",
              "  192,\n",
              "  213,\n",
              "  61,\n",
              "  212,\n",
              "  243,\n",
              "  409,\n",
              "  77,\n",
              "  160,\n",
              "  95,\n",
              "  149,\n",
              "  42,\n",
              "  57,\n",
              "  37,\n",
              "  107,\n",
              "  429,\n",
              "  186,\n",
              "  65,\n",
              "  230,\n",
              "  11,\n",
              "  135,\n",
              "  87,\n",
              "  220,\n",
              "  322,\n",
              "  77,\n",
              "  119,\n",
              "  125,\n",
              "  35,\n",
              "  149,\n",
              "  117,\n",
              "  222,\n",
              "  123,\n",
              "  73,\n",
              "  1101,\n",
              "  187,\n",
              "  51,\n",
              "  62,\n",
              "  115,\n",
              "  228,\n",
              "  23,\n",
              "  278,\n",
              "  308,\n",
              "  299,\n",
              "  76,\n",
              "  169,\n",
              "  199,\n",
              "  201,\n",
              "  51,\n",
              "  69,\n",
              "  160,\n",
              "  163,\n",
              "  262,\n",
              "  64,\n",
              "  174,\n",
              "  467,\n",
              "  45,\n",
              "  50,\n",
              "  170,\n",
              "  254,\n",
              "  35,\n",
              "  289,\n",
              "  175,\n",
              "  184,\n",
              "  149,\n",
              "  194,\n",
              "  46,\n",
              "  206,\n",
              "  112,\n",
              "  252,\n",
              "  137,\n",
              "  128,\n",
              "  16,\n",
              "  102,\n",
              "  282,\n",
              "  125,\n",
              "  197,\n",
              "  159,\n",
              "  50,\n",
              "  241,\n",
              "  216,\n",
              "  95,\n",
              "  291,\n",
              "  120,\n",
              "  127,\n",
              "  208,\n",
              "  64,\n",
              "  118,\n",
              "  102,\n",
              "  349,\n",
              "  54,\n",
              "  327,\n",
              "  165,\n",
              "  19,\n",
              "  133,\n",
              "  195,\n",
              "  261,\n",
              "  167,\n",
              "  140,\n",
              "  60,\n",
              "  541,\n",
              "  87,\n",
              "  45,\n",
              "  308,\n",
              "  120,\n",
              "  577,\n",
              "  209,\n",
              "  39,\n",
              "  332,\n",
              "  416,\n",
              "  67,\n",
              "  113,\n",
              "  29,\n",
              "  396,\n",
              "  31,\n",
              "  289,\n",
              "  310,\n",
              "  82,\n",
              "  67,\n",
              "  8,\n",
              "  153,\n",
              "  70,\n",
              "  35,\n",
              "  210,\n",
              "  207,\n",
              "  176,\n",
              "  22,\n",
              "  106,\n",
              "  56,\n",
              "  145,\n",
              "  218,\n",
              "  633,\n",
              "  35,\n",
              "  380,\n",
              "  116,\n",
              "  464,\n",
              "  157,\n",
              "  115,\n",
              "  156,\n",
              "  135,\n",
              "  338,\n",
              "  306,\n",
              "  84,\n",
              "  224,\n",
              "  421,\n",
              "  487,\n",
              "  90,\n",
              "  58,\n",
              "  402,\n",
              "  130,\n",
              "  169,\n",
              "  62,\n",
              "  285,\n",
              "  119,\n",
              "  51,\n",
              "  32,\n",
              "  179,\n",
              "  166,\n",
              "  170,\n",
              "  104,\n",
              "  53,\n",
              "  237,\n",
              "  12,\n",
              "  529,\n",
              "  41,\n",
              "  247,\n",
              "  102,\n",
              "  97,\n",
              "  158,\n",
              "  198,\n",
              "  8,\n",
              "  67,\n",
              "  151,\n",
              "  228,\n",
              "  193,\n",
              "  437,\n",
              "  89,\n",
              "  352,\n",
              "  289,\n",
              "  36,\n",
              "  322,\n",
              "  141,\n",
              "  118,\n",
              "  174,\n",
              "  112,\n",
              "  182,\n",
              "  28,\n",
              "  184,\n",
              "  284,\n",
              "  68,\n",
              "  82,\n",
              "  317,\n",
              "  115,\n",
              "  119,\n",
              "  136,\n",
              "  75,\n",
              "  182,\n",
              "  257,\n",
              "  318,\n",
              "  165,\n",
              "  354,\n",
              "  278,\n",
              "  196,\n",
              "  56,\n",
              "  53,\n",
              "  604,\n",
              "  99,\n",
              "  103,\n",
              "  209,\n",
              "  198,\n",
              "  221,\n",
              "  178,\n",
              "  237,\n",
              "  244,\n",
              "  143,\n",
              "  56,\n",
              "  27,\n",
              "  136,\n",
              "  35,\n",
              "  84,\n",
              "  31,\n",
              "  210,\n",
              "  135,\n",
              "  111,\n",
              "  26,\n",
              "  188,\n",
              "  46,\n",
              "  303,\n",
              "  137,\n",
              "  133,\n",
              "  169,\n",
              "  160,\n",
              "  286,\n",
              "  393,\n",
              "  174,\n",
              "  155,\n",
              "  193,\n",
              "  266,\n",
              "  244,\n",
              "  84,\n",
              "  266,\n",
              "  306,\n",
              "  145,\n",
              "  308,\n",
              "  177,\n",
              "  144,\n",
              "  154,\n",
              "  182,\n",
              "  269,\n",
              "  160,\n",
              "  375,\n",
              "  135,\n",
              "  131,\n",
              "  147,\n",
              "  138,\n",
              "  347,\n",
              "  91,\n",
              "  159,\n",
              "  74,\n",
              "  16,\n",
              "  43,\n",
              "  119,\n",
              "  45,\n",
              "  21,\n",
              "  175,\n",
              "  77,\n",
              "  2060,\n",
              "  117,\n",
              "  98,\n",
              "  275,\n",
              "  354,\n",
              "  182,\n",
              "  483,\n",
              "  214,\n",
              "  16,\n",
              "  167,\n",
              "  216,\n",
              "  82,\n",
              "  342,\n",
              "  172,\n",
              "  51,\n",
              "  406,\n",
              "  66,\n",
              "  179,\n",
              "  7,\n",
              "  9,\n",
              "  241,\n",
              "  104,\n",
              "  223,\n",
              "  61,\n",
              "  142,\n",
              "  179,\n",
              "  14,\n",
              "  163,\n",
              "  217,\n",
              "  217,\n",
              "  104,\n",
              "  106,\n",
              "  185,\n",
              "  210,\n",
              "  275,\n",
              "  76,\n",
              "  301,\n",
              "  220,\n",
              "  6,\n",
              "  380,\n",
              "  122,\n",
              "  739,\n",
              "  56,\n",
              "  77,\n",
              "  190,\n",
              "  3080,\n",
              "  182,\n",
              "  84,\n",
              "  105,\n",
              "  88,\n",
              "  199,\n",
              "  132,\n",
              "  73,\n",
              "  179,\n",
              "  327,\n",
              "  83,\n",
              "  189,\n",
              "  265,\n",
              "  65,\n",
              "  237,\n",
              "  423,\n",
              "  249,\n",
              "  46,\n",
              "  143,\n",
              "  99,\n",
              "  89,\n",
              "  129,\n",
              "  71,\n",
              "  207,\n",
              "  169,\n",
              "  63,\n",
              "  91,\n",
              "  156,\n",
              "  39,\n",
              "  288,\n",
              "  145,\n",
              "  195,\n",
              "  215,\n",
              "  249,\n",
              "  134,\n",
              "  19,\n",
              "  318,\n",
              "  48,\n",
              "  6,\n",
              "  457,\n",
              "  58,\n",
              "  271,\n",
              "  81,\n",
              "  56,\n",
              "  278,\n",
              "  83,\n",
              "  173,\n",
              "  98,\n",
              "  361,\n",
              "  92,\n",
              "  199,\n",
              "  351,\n",
              "  48,\n",
              "  267,\n",
              "  93,\n",
              "  178,\n",
              "  52,\n",
              "  44,\n",
              "  268,\n",
              "  29,\n",
              "  55,\n",
              "  204,\n",
              "  176,\n",
              "  288,\n",
              "  234,\n",
              "  31,\n",
              "  9,\n",
              "  66,\n",
              "  204,\n",
              "  116,\n",
              "  273,\n",
              "  202,\n",
              "  97,\n",
              "  49,\n",
              "  99,\n",
              "  346,\n",
              "  193,\n",
              "  189,\n",
              "  20,\n",
              "  51,\n",
              "  93,\n",
              "  226,\n",
              "  197,\n",
              "  323,\n",
              "  232,\n",
              "  76,\n",
              "  75,\n",
              "  251,\n",
              "  98,\n",
              "  44,\n",
              "  784,\n",
              "  37,\n",
              "  103,\n",
              "  28,\n",
              "  284,\n",
              "  247,\n",
              "  279,\n",
              "  337,\n",
              "  33,\n",
              "  43,\n",
              "  137,\n",
              "  166,\n",
              "  21,\n",
              "  258,\n",
              "  140,\n",
              "  66,\n",
              "  75,\n",
              "  209,\n",
              "  87,\n",
              "  128,\n",
              "  187,\n",
              "  100,\n",
              "  40,\n",
              "  148,\n",
              "  76,\n",
              "  145,\n",
              "  227,\n",
              "  245,\n",
              "  204,\n",
              "  10,\n",
              "  231,\n",
              "  149,\n",
              "  417,\n",
              "  209,\n",
              "  149,\n",
              "  128,\n",
              "  115,\n",
              "  70,\n",
              "  238,\n",
              "  311,\n",
              "  79,\n",
              "  291,\n",
              "  133,\n",
              "  149,\n",
              "  251,\n",
              "  267,\n",
              "  255,\n",
              "  115,\n",
              "  199,\n",
              "  35,\n",
              "  97,\n",
              "  46,\n",
              "  301,\n",
              "  186,\n",
              "  81,\n",
              "  52,\n",
              "  65,\n",
              "  70,\n",
              "  105,\n",
              "  121,\n",
              "  167,\n",
              "  146,\n",
              "  25,\n",
              "  188,\n",
              "  278,\n",
              "  61,\n",
              "  87,\n",
              "  224,\n",
              "  30,\n",
              "  129,\n",
              "  676,\n",
              "  492,\n",
              "  197,\n",
              "  283,\n",
              "  48,\n",
              "  483,\n",
              "  109,\n",
              "  238,\n",
              "  259,\n",
              "  33,\n",
              "  380,\n",
              "  47,\n",
              "  76,\n",
              "  124,\n",
              "  69,\n",
              "  99,\n",
              "  62,\n",
              "  186,\n",
              "  31,\n",
              "  73,\n",
              "  349,\n",
              "  287,\n",
              "  181,\n",
              "  80,\n",
              "  110,\n",
              "  710,\n",
              "  74,\n",
              "  222,\n",
              "  13,\n",
              "  297,\n",
              "  407,\n",
              "  195,\n",
              "  27,\n",
              "  106,\n",
              "  37,\n",
              "  39,\n",
              "  414,\n",
              "  151,\n",
              "  185,\n",
              "  80,\n",
              "  211,\n",
              "  233,\n",
              "  179,\n",
              "  216,\n",
              "  104,\n",
              "  67,\n",
              "  160,\n",
              "  54,\n",
              "  125,\n",
              "  452,\n",
              "  98,\n",
              "  24,\n",
              "  257,\n",
              "  74,\n",
              "  156,\n",
              "  194,\n",
              "  123,\n",
              "  238,\n",
              "  90,\n",
              "  149,\n",
              "  173,\n",
              "  121,\n",
              "  168,\n",
              "  174,\n",
              "  80,\n",
              "  221,\n",
              "  105,\n",
              "  38,\n",
              "  209,\n",
              "  242,\n",
              "  522,\n",
              "  119,\n",
              "  53,\n",
              "  217,\n",
              "  97,\n",
              "  118,\n",
              "  94,\n",
              "  20,\n",
              "  79,\n",
              "  76,\n",
              "  106,\n",
              "  182,\n",
              "  90,\n",
              "  97,\n",
              "  100,\n",
              "  197,\n",
              "  176,\n",
              "  43,\n",
              "  159,\n",
              "  26,\n",
              "  271,\n",
              "  63,\n",
              "  113,\n",
              "  250,\n",
              "  193,\n",
              "  39,\n",
              "  52,\n",
              "  226,\n",
              "  67,\n",
              "  120,\n",
              "  111,\n",
              "  182,\n",
              "  225,\n",
              "  254,\n",
              "  144,\n",
              "  70,\n",
              "  201,\n",
              "  225,\n",
              "  113,\n",
              "  69,\n",
              "  225,\n",
              "  168,\n",
              "  10,\n",
              "  61,\n",
              "  121,\n",
              "  347,\n",
              "  157,\n",
              "  184,\n",
              "  55,\n",
              "  124,\n",
              "  88,\n",
              "  207,\n",
              "  39,\n",
              "  142,\n",
              "  67,\n",
              "  97,\n",
              "  79,\n",
              "  280,\n",
              "  262,\n",
              "  51,\n",
              "  152,\n",
              "  415,\n",
              "  127,\n",
              "  264,\n",
              "  227,\n",
              "  415,\n",
              "  75,\n",
              "  242,\n",
              "  23,\n",
              "  484,\n",
              "  6,\n",
              "  108,\n",
              "  59,\n",
              "  70,\n",
              "  59,\n",
              "  360,\n",
              "  35,\n",
              "  200,\n",
              "  40,\n",
              "  259,\n",
              "  73,\n",
              "  74,\n",
              "  130,\n",
              "  110,\n",
              "  91,\n",
              "  90,\n",
              "  267,\n",
              "  151,\n",
              "  36,\n",
              "  7,\n",
              "  76,\n",
              "  207,\n",
              "  88,\n",
              "  70,\n",
              "  112,\n",
              "  354,\n",
              "  157,\n",
              "  135,\n",
              "  141,\n",
              "  152,\n",
              "  71,\n",
              "  287,\n",
              "  147,\n",
              "  314,\n",
              "  35,\n",
              "  281,\n",
              "  346,\n",
              "  289,\n",
              "  66,\n",
              "  84,\n",
              "  80,\n",
              "  41,\n",
              "  80,\n",
              "  190,\n",
              "  153,\n",
              "  469,\n",
              "  256,\n",
              "  113,\n",
              "  165,\n",
              "  109,\n",
              "  132,\n",
              "  132,\n",
              "  612,\n",
              "  173,\n",
              "  302,\n",
              "  215,\n",
              "  35,\n",
              "  624,\n",
              "  222,\n",
              "  343,\n",
              "  36,\n",
              "  79,\n",
              "  353,\n",
              "  269,\n",
              "  165,\n",
              "  133,\n",
              "  134,\n",
              "  176,\n",
              "  95,\n",
              "  131,\n",
              "  404,\n",
              "  89,\n",
              "  129,\n",
              "  120,\n",
              "  246,\n",
              "  44,\n",
              "  82,\n",
              "  109,\n",
              "  260,\n",
              "  86,\n",
              "  119,\n",
              "  23,\n",
              "  124,\n",
              "  150,\n",
              "  182,\n",
              "  35,\n",
              "  7,\n",
              "  189,\n",
              "  152,\n",
              "  222,\n",
              "  157,\n",
              "  50,\n",
              "  228,\n",
              "  47,\n",
              "  275,\n",
              "  229,\n",
              "  50,\n",
              "  501,\n",
              "  32,\n",
              "  133,\n",
              "  15,\n",
              "  75,\n",
              "  138,\n",
              "  123,\n",
              "  369,\n",
              "  266,\n",
              "  92,\n",
              "  64,\n",
              "  63,\n",
              "  322,\n",
              "  93,\n",
              "  205,\n",
              "  97,\n",
              "  37,\n",
              "  30,\n",
              "  32,\n",
              "  40,\n",
              "  93,\n",
              "  83,\n",
              "  405,\n",
              "  78,\n",
              "  63,\n",
              "  382,\n",
              "  59,\n",
              "  150,\n",
              "  236,\n",
              "  88,\n",
              "  317,\n",
              "  158,\n",
              "  180,\n",
              "  35,\n",
              "  357,\n",
              "  77,\n",
              "  57,\n",
              "  605,\n",
              "  60,\n",
              "  99,\n",
              "  108,\n",
              "  95,\n",
              "  85,\n",
              "  575,\n",
              "  225,\n",
              "  67,\n",
              "  102,\n",
              "  103,\n",
              "  41,\n",
              "  49,\n",
              "  94,\n",
              "  130,\n",
              "  323,\n",
              "  521,\n",
              "  208,\n",
              "  48,\n",
              "  244,\n",
              "  166,\n",
              "  278,\n",
              "  226,\n",
              "  50,\n",
              "  337,\n",
              "  91,\n",
              "  194,\n",
              "  257,\n",
              "  92,\n",
              "  151,\n",
              "  443,\n",
              "  98,\n",
              "  167,\n",
              "  154,\n",
              "  82,\n",
              "  53,\n",
              "  60,\n",
              "  85,\n",
              "  65,\n",
              "  81,\n",
              "  136,\n",
              "  272,\n",
              "  109,\n",
              "  235,\n",
              "  495,\n",
              "  72,\n",
              "  47,\n",
              "  49,\n",
              "  130,\n",
              "  192,\n",
              "  61,\n",
              "  259,\n",
              "  402,\n",
              "  211,\n",
              "  165,\n",
              "  140,\n",
              "  308,\n",
              "  195,\n",
              "  20,\n",
              "  103,\n",
              "  43,\n",
              "  181,\n",
              "  543,\n",
              "  54,\n",
              "  100,\n",
              "  59,\n",
              "  93,\n",
              "  106,\n",
              "  322,\n",
              "  98,\n",
              "  41,\n",
              "  21,\n",
              "  455,\n",
              "  51,\n",
              "  30,\n",
              "  16,\n",
              "  243,\n",
              "  548,\n",
              "  453,\n",
              "  92,\n",
              "  83,\n",
              "  69,\n",
              "  33,\n",
              "  65,\n",
              "  64,\n",
              "  35,\n",
              "  312,\n",
              "  240,\n",
              "  89,\n",
              "  119,\n",
              "  27,\n",
              "  67,\n",
              "  72,\n",
              "  119,\n",
              "  174,\n",
              "  43,\n",
              "  41,\n",
              "  101,\n",
              "  246,\n",
              "  69,\n",
              "  95,\n",
              "  159,\n",
              "  98,\n",
              "  44,\n",
              "  315,\n",
              "  133,\n",
              "  122,\n",
              "  39,\n",
              "  192,\n",
              "  75,\n",
              "  263,\n",
              "  90,\n",
              "  167,\n",
              "  203,\n",
              "  96,\n",
              "  82,\n",
              "  152,\n",
              "  332,\n",
              "  85,\n",
              "  79,\n",
              "  168,\n",
              "  200,\n",
              "  196,\n",
              "  15,\n",
              "  247,\n",
              "  91,\n",
              "  111,\n",
              "  113,\n",
              "  61,\n",
              "  98,\n",
              "  592,\n",
              "  419,\n",
              "  146,\n",
              "  35,\n",
              "  56,\n",
              "  249,\n",
              "  222,\n",
              "  482,\n",
              "  174,\n",
              "  26,\n",
              "  146,\n",
              "  26,\n",
              "  106,\n",
              "  149,\n",
              "  197,\n",
              "  228,\n",
              "  163,\n",
              "  114,\n",
              "  41,\n",
              "  64,\n",
              "  26,\n",
              "  69,\n",
              "  106,\n",
              "  25,\n",
              "  391,\n",
              "  38,\n",
              "  185,\n",
              "  118,\n",
              "  63,\n",
              "  158,\n",
              "  53,\n",
              "  63,\n",
              "  125,\n",
              "  250,\n",
              "  3,\n",
              "  444,\n",
              "  188,\n",
              "  24,\n",
              "  124,\n",
              "  31,\n",
              "  210,\n",
              "  79,\n",
              "  46,\n",
              "  5,\n",
              "  38,\n",
              "  91,\n",
              "  502,\n",
              "  249,\n",
              "  141,\n",
              "  31,\n",
              "  ...],\n",
              " {'min': 1,\n",
              "  'max': 3577,\n",
              "  'mean': 172.94638625592418,\n",
              "  'median': 133.0,\n",
              "  'std': 158.48273234081685})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "analyze_sequence_lengths(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyL9mLR0wQ1I",
        "outputId": "1d48c884-c6c6-4282-e3b0-455af9f00b39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: 30384\n",
            "Filtered dataset size: 26247\n",
            "Kept 86.38% of the data\n"
          ]
        }
      ],
      "source": [
        "filtered_df = filter_short_sequences(results_df, max_length_threshold=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zePezfE1wWJx",
        "outputId": "a115ff4b-7882-4853-a388-dcc5de3a8344"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.0007391 , 0.25756836, ..., 0.        , 0.        ,\n",
              "       0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "filtered_df['numpy_array'][1][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0s2QpD9wZEh"
      },
      "outputs": [],
      "source": [
        "def analyze_translation_lengths(filtered_df):\n",
        "    # Analyze word counts in translations\n",
        "    word_counts = [len(text.split()) for text in filtered_df['translation']]\n",
        "\n",
        "    return {\n",
        "        'min_words': min(word_counts),\n",
        "        'max_words': max(word_counts),\n",
        "        'avg_words': np.mean(word_counts),\n",
        "        'median_words': np.median(word_counts)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0feHmNE3wcQg",
        "outputId": "d8392023-8333-4dd2-c4c9-7ee9d428a2f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'min_words': 1,\n",
              " 'max_words': 383,\n",
              " 'avg_words': 14.576789728349906,\n",
              " 'median_words': 13.0}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "analyze_translation_lengths(filtered_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8iTNKGiwfF4"
      },
      "outputs": [],
      "source": [
        "def prepare_filtered_dataset():\n",
        "    # 1. First analyze the data\n",
        "    lengths, stats = analyze_sequence_lengths(results_df)\n",
        "    print(\"Original sequence statistics:\", stats)\n",
        "\n",
        "    # 2. Filter short sequences\n",
        "    filtered_df = filter_short_sequences(results_df, max_length_threshold=300)\n",
        "\n",
        "    # 3. Analyze translation complexity\n",
        "    translation_stats = analyze_translation_lengths(filtered_df)\n",
        "    print(\"Translation statistics:\", translation_stats)\n",
        "\n",
        "    return filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "TNhXlM9CwhrT",
        "outputId": "5a9bad21-f4bd-4ace-c71c-b8f356839979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sequence statistics: {'min': 1, 'max': 3577, 'mean': 172.94638625592418, 'median': 133.0, 'std': 158.48273234081685}\n",
            "Original dataset size: 30384\n",
            "Filtered dataset size: 26247\n",
            "Kept 86.38% of the data\n",
            "Translation statistics: {'min_words': 1, 'max_words': 383, 'avg_words': 14.576789728349906, 'median_words': 13.0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               id  \\\n",
              "1       b9nWwzf0C5E_9-5-rgb_front   \n",
              "2       -fyFTnt9w9Q_4-5-rgb_front   \n",
              "3       f8ShD9YwEfo_5-2-rgb_front   \n",
              "4       5Oq-F-EC_pU_9-8-rgb_front   \n",
              "5       1cUIexb0ELM_8-8-rgb_front   \n",
              "...                           ...   \n",
              "30376  15bYoBr7BWs_20-8-rgb_front   \n",
              "30378   2WTWOS8bF7A_7-3-rgb_front   \n",
              "30379   c6difzHesqQ_6-8-rgb_front   \n",
              "30380  c2KLK-rr89U_20-8-rgb_front   \n",
              "30383   -EdUkSqns3U_6-3-rgb_front   \n",
              "\n",
              "                                             translation  \\\n",
              "1      Now, from this position pick up your foot and ...   \n",
              "2                    So just think of your backhand now.   \n",
              "3      But what it'll do is it'll bring up a window o...   \n",
              "4                                They also fold back up.   \n",
              "5      You're only one swing thought away from hookin...   \n",
              "...                                                  ...   \n",
              "30376             Now, these are really easy to turn on.   \n",
              "30378  There you go, so now she has the super glossy ...   \n",
              "30379                                    Hi, hey, pause.   \n",
              "30380            And automatically, our cat looks angry.   \n",
              "30383  So, if I want combinations that add up to thir...   \n",
              "\n",
              "                                             numpy_array  \n",
              "1      [[0.0, 0.00022244453, 0.24072266, 0.0, 0.02577...  \n",
              "2      [[0.030654907, 0.020111084, 0.03955078, 0.1687...  \n",
              "3      [[0.056274414, 0.0, 0.0, 0.068237305, 0.0, 0.3...  \n",
              "4      [[0.0, 0.14453125, 0.0, 0.3569336, 0.004905700...  \n",
              "5      [[0.0, 0.0, 0.068725586, 0.019378662, 0.0, 0.0...  \n",
              "...                                                  ...  \n",
              "30376  [[0.0, 0.057556152, 0.0, 0.0, 0.0010938644, 0....  \n",
              "30378  [[0.0, 0.0, 0.00047302246, 0.0, 0.0, 0.0544433...  \n",
              "30379  [[0.04119873, 0.0, 0.0, 0.03503418, 0.0, 0.163...  \n",
              "30380  [[0.0, 0.17492676, 0.0, 0.0, 0.14465332, 0.0, ...  \n",
              "30383  [[0.0, 0.0, 0.0013189316, 0.0, 0.0, 0.05612182...  \n",
              "\n",
              "[26247 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1adcaa2c-63b6-4dde-8b8d-dbd9f20ca29b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>translation</th>\n",
              "      <th>numpy_array</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b9nWwzf0C5E_9-5-rgb_front</td>\n",
              "      <td>Now, from this position pick up your foot and ...</td>\n",
              "      <td>[[0.0, 0.00022244453, 0.24072266, 0.0, 0.02577...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-fyFTnt9w9Q_4-5-rgb_front</td>\n",
              "      <td>So just think of your backhand now.</td>\n",
              "      <td>[[0.030654907, 0.020111084, 0.03955078, 0.1687...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>f8ShD9YwEfo_5-2-rgb_front</td>\n",
              "      <td>But what it'll do is it'll bring up a window o...</td>\n",
              "      <td>[[0.056274414, 0.0, 0.0, 0.068237305, 0.0, 0.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5Oq-F-EC_pU_9-8-rgb_front</td>\n",
              "      <td>They also fold back up.</td>\n",
              "      <td>[[0.0, 0.14453125, 0.0, 0.3569336, 0.004905700...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1cUIexb0ELM_8-8-rgb_front</td>\n",
              "      <td>You're only one swing thought away from hookin...</td>\n",
              "      <td>[[0.0, 0.0, 0.068725586, 0.019378662, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30376</th>\n",
              "      <td>15bYoBr7BWs_20-8-rgb_front</td>\n",
              "      <td>Now, these are really easy to turn on.</td>\n",
              "      <td>[[0.0, 0.057556152, 0.0, 0.0, 0.0010938644, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30378</th>\n",
              "      <td>2WTWOS8bF7A_7-3-rgb_front</td>\n",
              "      <td>There you go, so now she has the super glossy ...</td>\n",
              "      <td>[[0.0, 0.0, 0.00047302246, 0.0, 0.0, 0.0544433...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30379</th>\n",
              "      <td>c6difzHesqQ_6-8-rgb_front</td>\n",
              "      <td>Hi, hey, pause.</td>\n",
              "      <td>[[0.04119873, 0.0, 0.0, 0.03503418, 0.0, 0.163...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30380</th>\n",
              "      <td>c2KLK-rr89U_20-8-rgb_front</td>\n",
              "      <td>And automatically, our cat looks angry.</td>\n",
              "      <td>[[0.0, 0.17492676, 0.0, 0.0, 0.14465332, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30383</th>\n",
              "      <td>-EdUkSqns3U_6-3-rgb_front</td>\n",
              "      <td>So, if I want combinations that add up to thir...</td>\n",
              "      <td>[[0.0, 0.0, 0.0013189316, 0.0, 0.0, 0.05612182...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26247 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1adcaa2c-63b6-4dde-8b8d-dbd9f20ca29b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1adcaa2c-63b6-4dde-8b8d-dbd9f20ca29b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1adcaa2c-63b6-4dde-8b8d-dbd9f20ca29b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2cedc5ff-7fa9-467e-9260-c91a2a474554\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2cedc5ff-7fa9-467e-9260-c91a2a474554')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2cedc5ff-7fa9-467e-9260-c91a2a474554 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"prepare_filtered_dataset()\",\n  \"rows\": 26247,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26247,\n        \"samples\": [\n          \"1Vxwre210Oc_0-5-rgb_front\",\n          \"3RzgpH5Hg3I_13-5-rgb_front\",\n          \"Cu1rDgWOZ9w_3-8-rgb_front\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"translation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25286,\n        \"samples\": [\n          \"And it actually, you know, if you utilize it properly, it's an absolutely amazing tool.\",\n          \"One controls the arch, the other one controls the club head speed.\",\n          \"Today I'll be showing you how to remove your old doorknob, and replace it with a new one.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"numpy_array\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "prepare_filtered_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG7F0U0OwkTQ"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICV_IXmQwpHc"
      },
      "outputs": [],
      "source": [
        "def preprocess_translation(text):\n",
        "    # Remove special characters (except spaces)\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Add <START> and <END> tags\n",
        "    #text = f\"<START> {text.strip()} <END>\"\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zSEmf3zwrrv",
        "outputId": "71c9ce90-a038-4cfd-afbe-7030e067131a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               id  \\\n",
            "1       b9nWwzf0C5E_9-5-rgb_front   \n",
            "2       -fyFTnt9w9Q_4-5-rgb_front   \n",
            "3       f8ShD9YwEfo_5-2-rgb_front   \n",
            "4       5Oq-F-EC_pU_9-8-rgb_front   \n",
            "5       1cUIexb0ELM_8-8-rgb_front   \n",
            "...                           ...   \n",
            "30376  15bYoBr7BWs_20-8-rgb_front   \n",
            "30378   2WTWOS8bF7A_7-3-rgb_front   \n",
            "30379   c6difzHesqQ_6-8-rgb_front   \n",
            "30380  c2KLK-rr89U_20-8-rgb_front   \n",
            "30383   -EdUkSqns3U_6-3-rgb_front   \n",
            "\n",
            "                                             translation  \n",
            "1      now from this position pick up your foot and t...  \n",
            "2                     so just think of your backhand now  \n",
            "3      but what itll do is itll bring up a window on ...  \n",
            "4                                 they also fold back up  \n",
            "5      youre only one swing thought away from hooking...  \n",
            "...                                                  ...  \n",
            "30376               now these are really easy to turn on  \n",
            "30378  there you go so now she has the super glossy lips  \n",
            "30379                                       hi hey pause  \n",
            "30380              and automatically our cat looks angry  \n",
            "30383  so if i want combinations that add up to thirt...  \n",
            "\n",
            "[26247 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "filtered_df['translation'] = filtered_df['translation'].apply(preprocess_translation)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(filtered_df[['id', 'translation']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P3dbQ-_wwTU",
        "outputId": "a5317beb-9847-41af-9244-eb9f4f1b4ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300, 1024)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the target frame size\n",
        "target_frame_size = 300\n",
        "feature_dim = 1024  # Feature size per frame (already fixed)\n",
        "\n",
        "def pad_or_truncate(array, target_size, feature_dim):\n",
        "    num_frames = array.shape[0]\n",
        "    if num_frames < target_size:\n",
        "        # Pad with zeros\n",
        "        padding = np.zeros((target_size - num_frames, feature_dim))\n",
        "        padded_array = np.vstack((array, padding))\n",
        "    else:\n",
        "        # Truncate to target size\n",
        "        padded_array = array[:target_size]\n",
        "    return padded_array\n",
        "\n",
        "# Apply to the DataFrame\n",
        "filtered_df['padded_numpy_array'] = filtered_df['numpy_array'].apply(\n",
        "    lambda x: pad_or_truncate(x, target_frame_size, feature_dim)\n",
        ")\n",
        "\n",
        "# Check the result\n",
        "print(filtered_df['padded_numpy_array'].iloc[0].shape)  # Should be (300, 1024)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO52eCffw1fr",
        "outputId": "859f5488-465e-4b9e-f527-2e75c9ae575a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           input_ids  \\\n",
            "1  [tensor(230), tensor(45), tensor(48), tensor(1...   \n",
            "2  [tensor(78), tensor(131), tensor(317), tensor(...   \n",
            "3  [tensor(68), tensor(125), tensor(34), tensor(1...   \n",
            "4  [tensor(79), tensor(92), tensor(11750), tensor...   \n",
            "5  [tensor(39), tensor(15), tensor(163), tensor(8...   \n",
            "\n",
            "                                      attention_mask  \n",
            "1  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
            "2  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
            "3  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
            "4  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
            "5  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n"
          ]
        }
      ],
      "source": [
        "from transformers import T5Tokenizer\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "# Tokenize translations\n",
        "filtered_df['tokenized'] = filtered_df['translation'].apply(\n",
        "    lambda x: tokenizer(x, padding=\"max_length\", truncation=True, max_length=25, return_tensors=\"pt\")\n",
        ")\n",
        "\n",
        "# Split tokenized results into input IDs and attention masks\n",
        "filtered_df['input_ids'] = filtered_df['tokenized'].apply(lambda x: x['input_ids'].squeeze(0))\n",
        "filtered_df['attention_mask'] = filtered_df['tokenized'].apply(lambda x: x['attention_mask'].squeeze(0))\n",
        "\n",
        "# Drop the intermediate 'tokenized' column\n",
        "filtered_df = filtered_df.drop(columns=['tokenized'])\n",
        "\n",
        "# Verify the result\n",
        "print(filtered_df[['input_ids', 'attention_mask']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-vD8nvHw5ex",
        "outputId": "dac4b830-5917-4654-84ef-c0bb60e67052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 20997, Validation size: 2625, Test size: 2625\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "train_df, val_df = train_test_split(filtered_df, test_size=0.2, random_state=42)\n",
        "val_df, test_df = train_test_split(val_df, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Train size: {len(train_df)}, Validation size: {len(val_df)}, Test size: {len(test_df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv2iw2oZxPFn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class SignLanguageDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        return {\n",
        "            'video_features': torch.tensor(row['padded_numpy_array'], dtype=torch.float32),\n",
        "            'input_ids': torch.tensor(row['input_ids'], dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(row['attention_mask'], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SignLanguageDataset(train_df)\n",
        "val_dataset = SignLanguageDataset(val_df)\n",
        "test_dataset = SignLanguageDataset(test_df)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFJvDJcKxTGC",
        "outputId": "8c6f8ac4-974e-4cef-f903-2fb37dd79b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Features Shape: torch.Size([300, 1024])\n",
            "Input IDs Shape: torch.Size([25])\n",
            "Attention Mask Shape: torch.Size([25])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-a7a66b182a98>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'input_ids': torch.tensor(row['input_ids'], dtype=torch.long),\n",
            "<ipython-input-19-a7a66b182a98>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'attention_mask': torch.tensor(row['attention_mask'], dtype=torch.long)\n"
          ]
        }
      ],
      "source": [
        "# Inspect the first item of the train dataset to check if data is loaded correctly\n",
        "sample = train_dataset[0]\n",
        "print(f\"Video Features Shape: {sample['video_features'].shape}\")\n",
        "print(f\"Input IDs Shape: {sample['input_ids'].shape}\")\n",
        "print(f\"Attention Mask Shape: {sample['attention_mask'].shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ5MgLDyxVhZ",
        "outputId": "c11ae7bc-e8f7-45df-e0b2-f1e3ed787e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Features Batch Shape: torch.Size([8, 300, 1024])\n",
            "Input IDs Batch Shape: torch.Size([8, 25])\n",
            "Attention Mask Batch Shape: torch.Size([8, 25])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-a7a66b182a98>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'input_ids': torch.tensor(row['input_ids'], dtype=torch.long),\n",
            "<ipython-input-19-a7a66b182a98>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'attention_mask': torch.tensor(row['attention_mask'], dtype=torch.long)\n"
          ]
        }
      ],
      "source": [
        "# Get the first batch from the train_loader to check the data\n",
        "batch = next(iter(train_loader))\n",
        "print(f\"Video Features Batch Shape: {batch['video_features'].shape}\")\n",
        "print(f\"Input IDs Batch Shape: {batch['input_ids'].shape}\")\n",
        "print(f\"Attention Mask Batch Shape: {batch['attention_mask'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30AICzd0xYfb"
      },
      "outputs": [],
      "source": [
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "# Load the pretrained T5 model\n",
        "decoder = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmXgtTtXxdMF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers.modeling_outputs import BaseModelOutput\n",
        "\n",
        "class I3DEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, lstm_hidden_dim, num_layers=1, bidirectional=False):\n",
        "        super(I3DEncoder, self).__init__()\n",
        "        self.linear_proj = nn.Linear(input_dim, hidden_dim)  # Linear projection to match LSTM input size\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=hidden_dim,\n",
        "            hidden_size=lstm_hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        # Update the hidden dimension after LSTM (doubled if bidirectional)\n",
        "        self.hidden_dim = lstm_hidden_dim * (2 if bidirectional else 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_len, input_dim] (I3D features)\n",
        "        x = self.linear_proj(x)  # Shape: [batch_size, seq_len, hidden_dim]\n",
        "        lstm_out, _ = self.lstm(x)  # Shape: [batch_size, seq_len, lstm_hidden_dim]\n",
        "        return lstm_out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1D2jEdEPxmlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94b3683d-718f-48c7-f8b9-3c550d5174aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtbGUuZHxvnV"
      },
      "outputs": [],
      "source": [
        "class SignLanguageRecognitionModel(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(SignLanguageRecognitionModel, self).__init__()\n",
        "        self.encoder = encoder  # I3D Encoder\n",
        "        self.decoder = decoder  # T5 Decoder\n",
        "\n",
        "        # Add a linear layer to project encoder outputs to the correct dimension for the decoder\n",
        "        self.projection = nn.Linear(encoder.hidden_dim, decoder.config.d_model)\n",
        "\n",
        "    def forward(self, video_features, decoder_input_ids, attention_mask):\n",
        "        # Step 1: Pass video features through the encoder\n",
        "        encoder_outputs = self.encoder(video_features)\n",
        "\n",
        "        # Step 2: Project encoder outputs to the correct dimension\n",
        "        encoder_outputs = self.projection(encoder_outputs)\n",
        "\n",
        "        # Wrap encoder outputs in BaseModelOutput\n",
        "        encoder_outputs = BaseModelOutput(last_hidden_state=encoder_outputs)\n",
        "\n",
        "        # Step 3: Pass the projected features to the T5 decoder\n",
        "        decoder_outputs = self.decoder(\n",
        "            input_ids=None,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            encoder_outputs=encoder_outputs  # Pass BaseModelOutput to the decoder\n",
        "        )\n",
        "        return decoder_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQYdZZ1Ax0Pu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f16868b-918d-41ef-d512-35b7930bddfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SignLanguageRecognitionModel(\n",
              "  (encoder): I3DEncoder(\n",
              "    (linear_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (lstm): LSTM(512, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (decoder): T5ForConditionalGeneration(\n",
              "    (shared): Embedding(32128, 512)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              "  )\n",
              "  (projection): Linear(in_features=1024, out_features=512, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Define parameters\n",
        "input_dim = 1024  # I3D feature dimension\n",
        "hidden_dim = 512  # Dimension after linear projection\n",
        "lstm_hidden_dim = 512  # LSTM hidden state size\n",
        "num_layers = 2  # Number of LSTM layers\n",
        "bidirectional = True  # Use bidirectional LSTM\n",
        "decoder_hidden_dim = 512  # T5 decoder expects this hidden_dim\n",
        "\n",
        "# Initialize the LSTM-based I3DEncoder\n",
        "encoder = I3DEncoder(\n",
        "    input_dim=input_dim,\n",
        "    hidden_dim=hidden_dim,\n",
        "    lstm_hidden_dim=lstm_hidden_dim,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional\n",
        ")\n",
        "\n",
        "# Load the pre-trained T5 decoder\n",
        "decoder = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "\n",
        "# Create the Sign Language Recognition Model\n",
        "model = SignLanguageRecognitionModel(encoder, decoder)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkpDr90dzstA"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = AdamW(model_transformers.parameters(), lr=5e-5)\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ_KqtJkx3eM",
        "outputId": "29a07445-ec46-40de-ebc0-32cec9253673"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-a7a66b182a98>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'input_ids': torch.tensor(row['input_ids'], dtype=torch.long),\n",
            "<ipython-input-19-a7a66b182a98>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'attention_mask': torch.tensor(row['attention_mask'], dtype=torch.long)\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Training Loss: 4.3463, Validation Loss: 3.8806\n",
            "Epoch 2/50, Training Loss: 3.9872, Validation Loss: 3.7113\n",
            "Epoch 3/50, Training Loss: 3.8142, Validation Loss: 3.6206\n",
            "Epoch 4/50, Training Loss: 3.6815, Validation Loss: 3.5280\n",
            "Epoch 5/50, Training Loss: 3.5594, Validation Loss: 3.4556\n",
            "Epoch 6/50, Training Loss: 3.4308, Validation Loss: 3.3800\n",
            "Epoch 7/50, Training Loss: 3.3091, Validation Loss: 3.3310\n",
            "Epoch 8/50, Training Loss: 3.1915, Validation Loss: 3.2907\n",
            "Epoch 9/50, Training Loss: 3.0761, Validation Loss: 3.2729\n",
            "Epoch 10/50, Training Loss: 2.9642, Validation Loss: 3.2479\n",
            "Epoch 11/50, Training Loss: 2.8558, Validation Loss: 3.2364\n",
            "Epoch 12/50, Training Loss: 2.7458, Validation Loss: 3.2476\n",
            "Epoch 13/50, Training Loss: 2.6437, Validation Loss: 3.2668\n",
            "Epoch 14/50, Training Loss: 2.5403, Validation Loss: 3.2879\n",
            "Early stopping triggered!\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 50\n",
        "patience = 3  # Number of epochs to wait before stopping if no improvement\n",
        "best_val_loss = float('inf')  # Initialize the best validation loss to a high value\n",
        "patience_counter = 0  # Counter to track the patience\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        # Move data to the device\n",
        "        video_features = batch['video_features'].to(device)\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        labels = input_ids[:, 1:].contiguous()\n",
        "\n",
        "        # Create an attention mask for the video features\n",
        "        video_attention_mask = torch.ones(video_features.shape[:2], dtype=torch.long, device=device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(video_features, input_ids, video_attention_mask)\n",
        "        logits = outputs.logits  # Predicted token logits\n",
        "\n",
        "        # Get predictions excluding the last token (usually a special token like EOS)\n",
        "        predicted_tokens = logits[:, :-1, :].contiguous()\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(predicted_tokens.view(-1, predicted_tokens.size(-1)), labels.view(-1))\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate average training loss for this epoch\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            # Move data to the device\n",
        "            video_features = batch['video_features'].to(device)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            labels = input_ids[:, 1:].contiguous()\n",
        "            video_attention_mask = torch.ones(video_features.shape[:2], dtype=torch.long, device=device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(video_features, input_ids, video_attention_mask)\n",
        "            logits = outputs.logits\n",
        "            predicted_tokens = logits[:, :-1, :].contiguous()\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = loss_fn(predicted_tokens.view(-1, predicted_tokens.size(-1)), labels.view(-1))\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Check for improvement\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0  # Reset the patience counter\n",
        "        # Optionally, save the model\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/best_model2_with LSTM.pth\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered!\")\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved weights into the model\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/best_model2_with LSTM.pth\"))\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "D-FoSoS_h9WY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a97606-5b1e-4339-e6d3-4e2f515b7780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-0eb6f859cda7>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"/content/drive/MyDrive/best_model2_with LSTM.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SignLanguageRecognitionModel(\n",
              "  (encoder): I3DEncoder(\n",
              "    (linear_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (lstm): LSTM(512, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (decoder): T5ForConditionalGeneration(\n",
              "    (shared): Embedding(32128, 512)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              "  )\n",
              "  (projection): Linear(in_features=1024, out_features=512, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "expZAatCq5LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWTfEo_836Jn"
      },
      "outputs": [],
      "source": [
        "def predict(model, tokenizer, video_features, max_length=25):\n",
        "    \"\"\"\n",
        "    Generate predictions for given video features.\n",
        "\n",
        "    Args:\n",
        "        model (SignLanguageRecognitionModel): Trained model instance.\n",
        "        tokenizer (T5Tokenizer): Tokenizer used during preprocessing and training.\n",
        "        video_features (Union[np.ndarray, torch.Tensor]): Input video features of shape (seq_len, feature_dim).\n",
        "        max_length (int): Maximum length of the output sequence.\n",
        "\n",
        "    Returns:\n",
        "        str: Decoded prediction as text.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Convert video_features to a PyTorch tensor if it's a NumPy array\n",
        "        if isinstance(video_features, np.ndarray):\n",
        "            video_features = torch.from_numpy(video_features).float()\n",
        "\n",
        "        # Ensure video_features is on the correct device\n",
        "        video_features = video_features.to(device)\n",
        "\n",
        "        # Add a batch dimension to video features\n",
        "        video_features = video_features.unsqueeze(0)\n",
        "        print(video_features.shape)\n",
        "\n",
        "        # Create an attention mask for video features\n",
        "        video_attention_mask = torch.ones(video_features.shape[:2], dtype=torch.long, device=device)\n",
        "        print(video_attention_mask.shape)\n",
        "\n",
        "        # Generate the output sequence using the decoder\n",
        "        outputs = model.decoder.generate(\n",
        "            input_ids=None,  # No input sequence for T5 since it's decoder-only generation\n",
        "            encoder_outputs=BaseModelOutput(\n",
        "                last_hidden_state=model.projection(model.encoder(video_features))\n",
        "            ),\n",
        "            attention_mask=video_attention_mask,\n",
        "            max_length=max_length,\n",
        "            num_beams=2,  # Beam search for better predictions\n",
        "            early_stopping=True\n",
        "        )\n",
        "        print(outputs)\n",
        "\n",
        "        # Decode the generated token IDs to a string\n",
        "        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF-nAnRd4ClA",
        "outputId": "5492def7-69c3-4d7b-d632-850fe8fbaed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 300, 1024])\n",
            "torch.Size([1, 300])\n",
            "tensor([[   0,    3,   99,   39,   15,  352,   12,  241,   12, 3197,   34,   91,\n",
            "           13,    8, 2182,    1]])\n",
            "Predicted Translation: if youre going to want to pull it out of the bag\n"
          ]
        }
      ],
      "source": [
        "# Example video features tensor\n",
        "sample_video_features = filtered_df['padded_numpy_array'][4]  # Replace with actual video features\n",
        "\n",
        "# Predict the translation\n",
        "translation = predict(model, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {translation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1fPFDTrQHSgI",
        "outputId": "0db30e34-e551-4be7-e1bd-83fdf9b3ac94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'they also fold back up'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "filtered_df['translation'][4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts9zRKF-9brW",
        "outputId": "2e6a6f0b-4e5b-43d0-dc65-b95d0bbfa626"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 300, 1024])\n",
            "torch.Size([1, 300])\n",
            "tensor([[    0,     3,    23,    43,     3,     9, 15305,     1]])\n",
            "Predicted Translation: i have a zoom\n"
          ]
        }
      ],
      "source": [
        "# Example video features tensor\n",
        "sample_video_features = filtered_df['padded_numpy_array'][8932]  # Replace with actual video features\n",
        "\n",
        "# Predict the translation\n",
        "translation = predict(model, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {translation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Cey1XK9E9gkD",
        "outputId": "33dc90db-44f7-40b8-9a97-02ec0135c096"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the force and the velocity combined makes the ball go further'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_df['translation'][8932]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb_mTOl79o70",
        "outputId": "0137ff73-8b6a-4d9d-9b60-564a77d6b0a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 300, 1024])\n",
            "torch.Size([1, 300])\n",
            "tensor([[   0,    3,   88,    7,    3,    9,  779, 7523,   24,   54,  199,  376,\n",
            "          369,  223,   12,    8, 6476,    7,   11,    3,   88,   54,  199,  376,\n",
            "          369]])\n",
            "Predicted Translation: hes a major developer that can help him come back to the knees and he can help him come\n"
          ]
        }
      ],
      "source": [
        "# Example video features tensor\n",
        "sample_video_features = filtered_df['padded_numpy_array'][791]  # Replace with actual video features\n",
        "\n",
        "# Predict the translation\n",
        "translation = predict(model, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {translation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "s-HgTkr3944t",
        "outputId": "4204e4e9-a23e-4732-cf7d-c42895bce5ec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'and mainly besides just the warming and the holding of the joints it can help make them feel loved and wanted'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_df['translation'][791]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "def predict(model, tokenizer, video_features, max_length=25):\n",
        "    \"\"\"\n",
        "    Generate predictions for given video features.\n",
        "\n",
        "    Args:\n",
        "        model (SignLanguageRecognitionModel): Trained model instance.\n",
        "        tokenizer (T5Tokenizer): Tokenizer used during preprocessing and training.\n",
        "        video_features (Union[np.ndarray, torch.Tensor]): Input video features of shape (seq_len, feature_dim).\n",
        "        max_length (int): Maximum length of the output sequence.\n",
        "\n",
        "    Returns:\n",
        "        str: Decoded prediction as text.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Convert video_features to a PyTorch tensor\n",
        "        if isinstance(video_features, np.ndarray):\n",
        "            video_features = torch.from_numpy(video_features).float()\n",
        "\n",
        "        # Ensure video_features is on the correct device\n",
        "        video_features = video_features.to(device)\n",
        "\n",
        "        # Add a batch dimension to video features\n",
        "        video_features = video_features.unsqueeze(0)\n",
        "\n",
        "        # Create an attention mask for video features\n",
        "        video_attention_mask = torch.ones(video_features.shape[:2], dtype=torch.long, device=device)\n",
        "\n",
        "        # Generate the output sequence using the decoder\n",
        "        outputs = model.decoder.generate(\n",
        "            input_ids=None,\n",
        "            encoder_outputs=BaseModelOutput(\n",
        "                last_hidden_state=model.projection(model.encoder(video_features))\n",
        "            ),\n",
        "            attention_mask=video_attention_mask,\n",
        "            max_length=max_length,\n",
        "            num_beams=2,  # Beam search for better predictions\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        # Decode the generated token IDs to a string\n",
        "        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return prediction\n",
        "\n",
        "\n",
        "sample_video_features = filtered_df['padded_numpy_array'][14]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][14]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1u6jRyul0_0",
        "outputId": "c7960413-685f-4b39-8387-95d0fbfd7434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: youre going to be talking about how you can do it\n",
            "Ground Truth Translation: but depending on how you cook it you can tenderize it\n",
            "BLEU score: 0.05637560315259291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_video_features = filtered_df['padded_numpy_array'][5]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][5]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCIwAM-fhIQL",
        "outputId": "3996cfde-716e-4c30-b5b5-3c8f5136d549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: if youre not going to hit the ball and you want to be able to take it out\n",
            "Ground Truth Translation: youre only one swing thought away from hooking the ball and losing your slice and this could be it\n",
            "BLEU score: 0.0601429426464788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_video_features = filtered_df['padded_numpy_array'][13]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][13]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRj0jzrAmEhP",
        "outputId": "f77030f5-6238-45d6-dffe-340ff02c4aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: i think its important to remember to keep the thread on the other side so that you can stay on the other side\n",
            "Ground Truth Translation: so the rules get a little bit convoluted but its important to remember first of all to stay on the strip\n",
            "BLEU score: 0.1629944673128894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_video_features = filtered_df['padded_numpy_array'][3]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][3]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh7SBiGKmEd6",
        "outputId": "5d6cf882-a267-4384-c7e6-748482229232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: i have a process that you can do on your computer\n",
            "Ground Truth Translation: but what itll do is itll bring up a window on your computer that brings up the task manager\n",
            "BLEU score: 0.05361218207146106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_video_features = filtered_df['padded_numpy_array'][16]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][16]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnjH79WvmEcE",
        "outputId": "025adbd5-333d-459f-9b0a-7be58912affa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: i am going to talk about the power swings and the balance of the chest\n",
            "Ground Truth Translation: dont worry about your power dont worry about getting everything perfect just snap off a lot of punches\n",
            "BLEU score: 0.014242474285751547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_video_features = filtered_df['padded_numpy_array'][17]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][17]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-mEuwyvmEZ8",
        "outputId": "6f3e6135-7493-462e-a6b3-2760eae2655f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: a lot of people are going to need a car that has a little bit of a little bit of\n",
            "Ground Truth Translation: and doing this could be a little harder in smaller vehicle but it still could be done\n",
            "BLEU score: 0.020364851292391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_video_features = filtered_df['padded_numpy_array'][9]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][9]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHak5BE9mEYc",
        "outputId": "0ecb322c-07f8-4583-a752-65688463a0ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: i have a squat so i have a squat so i have\n",
            "Ground Truth Translation: but a good player that has the strokes once they get the wheel chair down youre in trouble\n",
            "BLEU score: 0.01033114956441737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_video_features = filtered_df['padded_numpy_array'][18]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][18]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar8NyPQEmEWl",
        "outputId": "ed6488aa-91b8-4355-bdb5-1190963beaff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: i need to get it done\n",
            "Ground Truth Translation: this is a flamingo catch\n",
            "BLEU score: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def calculate_dataset_bleu(model, tokenizer, dataloader, device):\n",
        "    \"\"\"\n",
        "    Calculate BLEU scores for an entire dataset\n",
        "\n",
        "    Args:\n",
        "        model: The trained model\n",
        "        tokenizer: The tokenizer used for text processing\n",
        "        dataloader: DataLoader containing the dataset\n",
        "        device: Device to run the model on\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing BLEU scores and predictions\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_bleu_scores = []\n",
        "    all_predictions = []\n",
        "    all_references = []\n",
        "    smoothing = SmoothingFunction().method1\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Use tqdm for progress bar\n",
        "        for batch in tqdm(dataloader, desc=\"Calculating BLEU scores\"):\n",
        "            # Get video features and reference text\n",
        "            video_features = batch['video_features'].to(device)\n",
        "\n",
        "            # Get reference texts by decoding input_ids\n",
        "            references = [tokenizer.decode(ids, skip_special_tokens=True)\n",
        "                         for ids in batch['input_ids']]\n",
        "\n",
        "            # Generate predictions for the batch\n",
        "            for i in range(len(video_features)):\n",
        "                video_feature = video_features[i].unsqueeze(0)\n",
        "                video_attention_mask = torch.ones(video_feature.shape[:2],\n",
        "                                               dtype=torch.long,\n",
        "                                               device=device)\n",
        "\n",
        "                # Generate prediction\n",
        "                outputs = model.decoder.generate(\n",
        "                    input_ids=None,\n",
        "                    encoder_outputs=BaseModelOutput(\n",
        "                        last_hidden_state=model.projection(model.encoder(video_feature))\n",
        "                    ),\n",
        "                    attention_mask=video_attention_mask,\n",
        "                    max_length=25,\n",
        "                    num_beams=2,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "                # Decode prediction\n",
        "                prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "                reference = references[i]\n",
        "\n",
        "                # Calculate BLEU score\n",
        "                reference_tokens = reference.split()\n",
        "                prediction_tokens = prediction.split()\n",
        "\n",
        "                bleu_score = sentence_bleu([reference_tokens],\n",
        "                                         prediction_tokens,\n",
        "                                         smoothing_function=smoothing)\n",
        "\n",
        "                all_bleu_scores.append(bleu_score)\n",
        "                all_predictions.append(prediction)\n",
        "                all_references.append(reference)\n",
        "\n",
        "    # Calculate statistics\n",
        "    results = {\n",
        "        'mean_bleu': np.mean(all_bleu_scores),\n",
        "        'median_bleu': np.median(all_bleu_scores),\n",
        "        'std_bleu': np.std(all_bleu_scores),\n",
        "        'min_bleu': np.min(all_bleu_scores),\n",
        "        'max_bleu': np.max(all_bleu_scores),\n",
        "        'bleu_scores': all_bleu_scores,\n",
        "\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "def evaluate_all_splits(model, tokenizer, train_loader, val_loader, test_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluate BLEU scores for all data splits\n",
        "    \"\"\"\n",
        "    print(\"Evaluating training set...\")\n",
        "    train_results = calculate_dataset_bleu(model, tokenizer, train_loader, device)\n",
        "\n",
        "    print(\"Evaluating validation set...\")\n",
        "    val_results = calculate_dataset_bleu(model, tokenizer, val_loader, device)\n",
        "\n",
        "    print(\"Evaluating test set...\")\n",
        "    test_results = calculate_dataset_bleu(model, tokenizer, test_loader, device)\n",
        "\n",
        "    # Create summary DataFrame\n",
        "    summary_data = {\n",
        "        'Metric': ['Mean BLEU', 'Median BLEU', 'Std BLEU', 'Min BLEU', 'Max BLEU'],\n",
        "        'Train': [train_results['mean_bleu'], train_results['median_bleu'],\n",
        "                 train_results['std_bleu'], train_results['min_bleu'],\n",
        "                 train_results['max_bleu']],\n",
        "        'Validation': [val_results['mean_bleu'], val_results['median_bleu'],\n",
        "                      val_results['std_bleu'], val_results['min_bleu'],\n",
        "                      val_results['max_bleu']],\n",
        "        'Test': [test_results['mean_bleu'], test_results['median_bleu'],\n",
        "                test_results['std_bleu'], test_results['min_bleu'],\n",
        "                test_results['max_bleu']]\n",
        "    }\n",
        "\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "    # Save detailed results\n",
        "    all_results = {\n",
        "        'train': train_results,\n",
        "        'validation': val_results,\n",
        "        'test': test_results,\n",
        "        'summary': summary_df\n",
        "    }\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# Function to save results to CSV files\n",
        "def save_results(results, output_dir='bleu_results'):\n",
        "    \"\"\"\n",
        "    Save evaluation results to CSV files\n",
        "    \"\"\"\n",
        "    import os\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save summary\n",
        "    results['summary'].to_csv(f'{output_dir}/summary_metrics.csv', index=False)\n",
        "\n",
        "    # Save detailed results for each split\n",
        "    for split in ['train', 'validation', 'test']:\n",
        "        detailed_df = pd.DataFrame({\n",
        "            'bleu_score': results[split]['bleu_scores']\n",
        "        })\n",
        "        detailed_df.to_csv(f'{output_dir}/{split}_detailed_results.csv', index=False)"
      ],
      "metadata": {
        "id": "v0S73qR3mGjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate_all_splits(model, tokenizer, train_loader, val_loader, test_loader, device)\n",
        "\n",
        "# Save the results to CSV\n",
        "save_results(results, output_dir='bleu_results')"
      ],
      "metadata": {
        "id": "9uYPe0QHmGgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb45a88a-2a08-4913-fe2f-c33b219e6f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating training set...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating BLEU scores:   0%|          | 0/2625 [00:00<?, ?it/s]<ipython-input-20-a7a66b182a98>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'input_ids': torch.tensor(row['input_ids'], dtype=torch.long),\n",
            "<ipython-input-20-a7a66b182a98>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'attention_mask': torch.tensor(row['attention_mask'], dtype=torch.long)\n",
            "Calculating BLEU scores: 100%|██████████| 2625/2625 [1:50:49<00:00,  2.53s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating validation set...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating BLEU scores: 100%|██████████| 329/329 [13:57<00:00,  2.54s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating BLEU scores: 100%|██████████| 329/329 [14:01<00:00,  2.56s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summery_df  = results['summary']"
      ],
      "metadata": {
        "id": "PxlqdZw2mGdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summery_df"
      ],
      "metadata": {
        "id": "nug1QUC4mGb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ff51a1de-511f-48f1-8762-a6fed430c72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Metric     Train  Validation      Test\n",
              "0    Mean BLEU  0.071204    0.047343  0.049382\n",
              "1  Median BLEU  0.025607    0.022024  0.021459\n",
              "2     Std BLEU  0.122937    0.080790  0.088023\n",
              "3     Min BLEU  0.000000    0.000000  0.000000\n",
              "4     Max BLEU  1.000000    0.846482  1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-178cba9f-37ef-49b4-be10-65f7b839c512\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Train</th>\n",
              "      <th>Validation</th>\n",
              "      <th>Test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mean BLEU</td>\n",
              "      <td>0.071204</td>\n",
              "      <td>0.047343</td>\n",
              "      <td>0.049382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Median BLEU</td>\n",
              "      <td>0.025607</td>\n",
              "      <td>0.022024</td>\n",
              "      <td>0.021459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Std BLEU</td>\n",
              "      <td>0.122937</td>\n",
              "      <td>0.080790</td>\n",
              "      <td>0.088023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Min BLEU</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Max BLEU</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.846482</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-178cba9f-37ef-49b4-be10-65f7b839c512')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-178cba9f-37ef-49b4-be10-65f7b839c512 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-178cba9f-37ef-49b4-be10-65f7b839c512');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6a0084a9-aae4-4485-9a6b-8f78ffc0148a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a0084a9-aae4-4485-9a6b-8f78ffc0148a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6a0084a9-aae4-4485-9a6b-8f78ffc0148a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8c7b761b-b2fa-4696-bb8a-2d5a50473a41\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summery_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8c7b761b-b2fa-4696-bb8a-2d5a50473a41 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summery_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summery_df",
              "summary": "{\n  \"name\": \"summery_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Median BLEU\",\n          \"Max BLEU\",\n          \"Std BLEU\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.42522990850753484,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.02560744480557418,\n          1.0,\n          0.12293747033663306\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3630176588172189,\n        \"min\": 0.0,\n        \"max\": 0.846481724890614,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.022023814946586635,\n          0.846481724890614,\n          0.080789557923037\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.43071279777444826,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.02145851237135921,\n          1.0,\n          0.08802330816769462\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_bleu_scores(df, model, tokenizer, split_name=\"\"):\n",
        "    \"\"\"\n",
        "    Calculate BLEU scores for all entries in a dataframe\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing the data\n",
        "        model: The trained model\n",
        "        tokenizer: The tokenizer\n",
        "        split_name (str): Name of the data split for printing purposes\n",
        "\n",
        "    Returns:\n",
        "        list: List of BLEU scores\n",
        "        dict: Dictionary containing statistics\n",
        "    \"\"\"\n",
        "    bleu_scores = []\n",
        "    predictions = []\n",
        "    references = []\n",
        "    smoothing_function = SmoothingFunction().method1\n",
        "\n",
        "    print(f\"\\nProcessing {split_name} split...\")\n",
        "\n",
        "    # Process each sample in the dataset\n",
        "    for idx in tqdm(range(len(df))):\n",
        "        # Get video features and ground truth\n",
        "        video_features = df['padded_numpy_array'].iloc[idx]\n",
        "        reference = df['translation'].iloc[idx]\n",
        "\n",
        "        # Get prediction\n",
        "        prediction = predict(model, tokenizer, video_features)\n",
        "\n",
        "        # Store predictions and references\n",
        "        predictions.append(prediction)\n",
        "        references.append(reference)\n",
        "\n",
        "        # Calculate BLEU score\n",
        "        reference_tokens = reference.split()\n",
        "        prediction_tokens = prediction.split()\n",
        "\n",
        "        try:\n",
        "            bleu = sentence_bleu([reference_tokens], prediction_tokens,\n",
        "                               smoothing_function=smoothing_function)\n",
        "            bleu_scores.append(bleu)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating BLEU score for index {idx}: {e}\")\n",
        "            bleu_scores.append(0.0)\n",
        "\n",
        "    # Calculate statistics\n",
        "    stats = {\n",
        "        'mean_bleu': np.mean(bleu_scores),\n",
        "        'median_bleu': np.median(bleu_scores),\n",
        "        'std_bleu': np.std(bleu_scores),\n",
        "        'min_bleu': np.min(bleu_scores),\n",
        "        'max_bleu': np.max(bleu_scores)\n",
        "    }\n",
        "\n",
        "    # Create a results DataFrame\n",
        "    results_df = pd.DataFrame({\n",
        "        'reference': references,\n",
        "        'prediction': predictions,\n",
        "        'bleu_score': bleu_scores\n",
        "    })\n",
        "\n",
        "    return bleu_scores, stats, results_df\n",
        "\n",
        "# Calculate BLEU scores for each split\n",
        "train_bleu, train_stats, train_results = calculate_bleu_scores(train_df, model, tokenizer, \"Training\")\n",
        "val_bleu, val_stats, val_results = calculate_bleu_scores(val_df, model, tokenizer, \"Validation\")\n",
        "test_bleu, test_stats, test_results = calculate_bleu_scores(test_df, model, tokenizer, \"Test\")\n",
        "\n",
        "# Print statistics for each split\n",
        "print(\"\\nTraining Set Statistics:\")\n",
        "for metric, value in train_stats.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "print(\"\\nValidation Set Statistics:\")\n",
        "for metric, value in val_stats.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "print(\"\\nTest Set Statistics:\")\n",
        "for metric, value in test_stats.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Save results to CSV files\n",
        "train_results.to_csv('train_results_lstm.csv', index=False)\n",
        "val_results.to_csv('val_results.csv_lstm', index=False)\n",
        "test_results.to_csv('test_results.csv_lstm', index=False)\n"
      ],
      "metadata": {
        "id": "Qe100xqSmEUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2178dc97-58f6-41ae-ff21-6b9496b9773b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing Training split...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20997/20997 [1:55:04<00:00,  3.04it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing Validation split...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2625/2625 [14:04<00:00,  3.11it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing Test split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2625/2625 [14:07<00:00,  3.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Set Statistics:\n",
            "mean_bleu: 0.0689\n",
            "median_bleu: 0.0247\n",
            "std_bleu: 0.1214\n",
            "min_bleu: 0.0000\n",
            "max_bleu: 1.0000\n",
            "\n",
            "Validation Set Statistics:\n",
            "mean_bleu: 0.0459\n",
            "median_bleu: 0.0207\n",
            "std_bleu: 0.0800\n",
            "min_bleu: 0.0000\n",
            "max_bleu: 0.8465\n",
            "\n",
            "Test Set Statistics:\n",
            "mean_bleu: 0.0478\n",
            "median_bleu: 0.0202\n",
            "std_bleu: 0.0870\n",
            "min_bleu: 0.0000\n",
            "max_bleu: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results to CSV files\n",
        "train_results.to_csv('train_results_lstm.csv', index=False)\n",
        "val_results.to_csv('val_results_lstm.csv', index=False)\n",
        "test_results.to_csv('test_results_lstm.csv', index=False)"
      ],
      "metadata": {
        "id": "q4MFhFFGhIMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T0oIXAdWhIKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wo2BHgFidhMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1JeCvnL1dg4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2kiO1ZgZdg0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wFxVtFtldgx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S9JLIP-LdgvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "G-rkOSzGhIIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers.modeling_outputs import BaseModelOutput"
      ],
      "metadata": {
        "id": "2w1uOhQiywRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ywWETm31N-t"
      },
      "source": [
        "Transformer Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54UmCKztzvUZ"
      },
      "outputs": [],
      "source": [
        "class I3DEncoder2(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, nhead, num_layers, ff_dim, dropout=0.1, max_seq_len=300):\n",
        "        # Change I3DEncoder to I3DEncoder2 to correctly call the superclass's __init__ method\n",
        "        super(I3DEncoder2, self).__init__()\n",
        "        self.linear_proj = nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # Positional encoding to provide sequence order information\n",
        "        self.positional_encoding = nn.Parameter(torch.zeros(1, max_seq_len, hidden_dim))\n",
        "\n",
        "        # Define Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_dim,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=ff_dim,\n",
        "            dropout=dropout\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_len, input_dim] (I3D features)\n",
        "        x = self.linear_proj(x)  # Project to Transformer input dimension: [batch_size, seq_len, hidden_dim]\n",
        "        x = x + self.positional_encoding[:, :x.size(1), :]  # Add positional encoding\n",
        "\n",
        "        # Pass through Transformer Encoder (requires [seq_len, batch_size, hidden_dim])\n",
        "        x = self.transformer(x.permute(1, 0, 2))  # [seq_len, batch_size, hidden_dim]\n",
        "        x = x.permute(1, 0, 2)  # Back to [batch_size, seq_len, hidden_dim]\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kGz266q1ShR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ebf1421-c421-4ccb-c823-9652677ae112"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SignLanguageRecognitionModel(\n",
              "  (encoder): I3DEncoder2(\n",
              "    (linear_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (transformer): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-3): 4 x TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.2, inplace=False)\n",
              "          (dropout2): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): T5ForConditionalGeneration(\n",
              "    (shared): Embedding(32128, 512)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              "  )\n",
              "  (projection): Linear(in_features=512, out_features=512, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Define parameters for Transformer Encoder\n",
        "input_dim = 1024  # I3D feature dimension\n",
        "hidden_dim = 512  # Hidden size for Transformer and T5 compatibility\n",
        "nhead = 8         # Number of attention heads\n",
        "num_layers = 4    # Number of Transformer layers\n",
        "ff_dim = 2048     # Feedforward network dimension\n",
        "dropout = 0.2     # Dropout rate\n",
        "\n",
        "# Initialize the Transformer-based I3DEncoder\n",
        "encoder = I3DEncoder2(\n",
        "    input_dim=input_dim,\n",
        "    hidden_dim=hidden_dim,\n",
        "    nhead=nhead,\n",
        "    num_layers=num_layers,\n",
        "    ff_dim=ff_dim,\n",
        "    dropout=dropout,\n",
        "    max_seq_len=300  # Assuming maximum sequence length is 300\n",
        ")\n",
        "\n",
        "# Load the pre-trained T5 decoder\n",
        "decoder = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "\n",
        "# Create the Sign Language Recognition Model\n",
        "model_transformers = SignLanguageRecognitionModel(encoder, decoder)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_transformers.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7px1Hfh24hy",
        "outputId": "26316e6e-f34c-4734-f902-d9aa94dae809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-a7a66b182a98>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'input_ids': torch.tensor(row['input_ids'], dtype=torch.long),\n",
            "<ipython-input-20-a7a66b182a98>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'attention_mask': torch.tensor(row['attention_mask'], dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Training Loss: 4.1133, Validation Loss: 3.8548\n",
            "Epoch 2/50, Training Loss: 3.9313, Validation Loss: 3.7490\n",
            "Epoch 3/50, Training Loss: 3.7823, Validation Loss: 3.7227\n",
            "Epoch 4/50, Training Loss: 3.6495, Validation Loss: 3.6544\n",
            "Epoch 5/50, Training Loss: 3.5157, Validation Loss: 3.6482\n",
            "Epoch 6/50, Training Loss: 3.3846, Validation Loss: 3.6139\n",
            "Epoch 7/50, Training Loss: 3.2514, Validation Loss: 3.6311\n",
            "Epoch 8/50, Training Loss: 3.1168, Validation Loss: 3.6505\n",
            "Early stopping triggered!\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 50\n",
        "patience = 2  # Number of epochs to wait before stopping if no improvement\n",
        "best_val_loss = float('inf')  # Initialize the best validation loss to a high value\n",
        "patience_counter = 0  # Counter to track the patience\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_transformers.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        # Move data to the device\n",
        "        video_features = batch['video_features'].to(device)\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        labels = input_ids[:, 1:].contiguous()\n",
        "\n",
        "        # Create an attention mask for the video features\n",
        "        video_attention_mask = torch.ones(video_features.shape[:2], dtype=torch.long, device=device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_transformers(video_features, input_ids, video_attention_mask)\n",
        "        logits = outputs.logits  # Predicted token logits\n",
        "\n",
        "        # Get predictions excluding the last token (usually a special token like EOS)\n",
        "        predicted_tokens = logits[:, :-1, :].contiguous()\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(predicted_tokens.view(-1, predicted_tokens.size(-1)), labels.view(-1))\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate average training loss for this epoch\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation phase\n",
        "    model_transformers.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            # Move data to the device\n",
        "            video_features = batch['video_features'].to(device)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            labels = input_ids[:, 1:].contiguous()\n",
        "            video_attention_mask = torch.ones(video_features.shape[:2], dtype=torch.long, device=device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model_transformers(video_features, input_ids, video_attention_mask)\n",
        "            logits = outputs.logits\n",
        "            predicted_tokens = logits[:, :-1, :].contiguous()\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = loss_fn(predicted_tokens.view(-1, predicted_tokens.size(-1)), labels.view(-1))\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Check for improvement\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0  # Reset the patience counter\n",
        "        # Optionally, save the model\n",
        "        torch.save(model_transformers.state_dict(), \"/content/drive/MyDrive/best_model_with_Transformers.pth\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered!\")\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved weights into the model\n",
        "model_transformers.load_state_dict(torch.load(\"/content/drive/MyDrive/best_model_with_Transformers.pth\"))\n",
        "model_transformers.to(device)\n"
      ],
      "metadata": {
        "id": "cYFKoub-qJh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8dcc212-f9cd-4d56-c5dd-dc666051da6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-9d66a49b4607>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_transformers.load_state_dict(torch.load(\"/content/drive/MyDrive/best_model_with_Transformers.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SignLanguageRecognitionModel(\n",
              "  (encoder): I3DEncoder2(\n",
              "    (linear_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (transformer): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-3): 4 x TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.2, inplace=False)\n",
              "          (dropout2): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): T5ForConditionalGeneration(\n",
              "    (shared): Embedding(32128, 512)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-5): 5 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              "  )\n",
              "  (projection): Linear(in_features=512, out_features=512, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "def predict(model, tokenizer, video_features, max_length=25):\n",
        "    \"\"\"\n",
        "    Generate predictions for given video features.\n",
        "\n",
        "    Args:\n",
        "        model (SignLanguageRecognitionModel): Trained model instance.\n",
        "        tokenizer (T5Tokenizer): Tokenizer used during preprocessing and training.\n",
        "        video_features (Union[np.ndarray, torch.Tensor]): Input video features of shape (seq_len, feature_dim).\n",
        "        max_length (int): Maximum length of the output sequence.\n",
        "\n",
        "    Returns:\n",
        "        str: Decoded prediction as text.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Convert video_features to a PyTorch tensor\n",
        "        if isinstance(video_features, np.ndarray):\n",
        "            video_features = torch.from_numpy(video_features).float()\n",
        "\n",
        "        # Ensure video_features is on the correct device\n",
        "        video_features = video_features.to(device)\n",
        "\n",
        "        # Add a batch dimension to video features\n",
        "        video_features = video_features.unsqueeze(0)\n",
        "\n",
        "        # Create an attention mask for video features\n",
        "        video_attention_mask = torch.ones(video_features.shape[:2], dtype=torch.long, device=device)\n",
        "\n",
        "        # Generate the output sequence using the decoder\n",
        "        outputs = model.decoder.generate(\n",
        "            input_ids=None,\n",
        "            encoder_outputs=BaseModelOutput(\n",
        "                last_hidden_state=model.projection(model.encoder(video_features))\n",
        "            ),\n",
        "            attention_mask=video_attention_mask,\n",
        "            max_length=max_length,\n",
        "            num_beams=2,  # Beam search for better predictions\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        # Decode the generated token IDs to a string\n",
        "        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return prediction\n",
        "\n",
        "\n",
        "sample_video_features = filtered_df['padded_numpy_array'][14]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model_transformers, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][14]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")\n"
      ],
      "metadata": {
        "id": "5XbjZAuiT1Bn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f109b9-aa5b-4ddd-ab8c-259caf8cdea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: i can roast it up with a little bit of a roaster\n",
            "Ground Truth Translation: but depending on how you cook it you can tenderize it\n",
            "BLEU score: 0.020255986027125642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpfzCYoR3WqM",
        "outputId": "c3319a72-4987-437f-f881-ababa2174084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: i have a sleeve and a sleeve\n"
          ]
        }
      ],
      "source": [
        "# Example video features tensor\n",
        "sample_video_features = filtered_df['padded_numpy_array'][4]  # Replace with actual video features\n",
        "\n",
        "# Predict the translation\n",
        "translation = predict(model_transformers, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {translation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc0PHPcH4NKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7f3277-34b0-4de9-b6a5-7c94f85da11f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth Translation: they also fold back up\n"
          ]
        }
      ],
      "source": [
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][4]\n",
        "print(f\"Ground Truth Translation: {reference}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shGA7mY9Ukx5",
        "outputId": "016999c3-b29c-4f5c-efa0-fb56f56251c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score: 0.017033186037639283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sample_video_features = filtered_df['padded_numpy_array'][5]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model_transformers, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][5]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9yFs9RRU_8q",
        "outputId": "c2db28cc-aa86-4209-eacf-f3a12ac18d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: if you want to hit the ball you want to take your swing to the right side of the ball so you can\n",
            "Ground Truth Translation: youre only one swing thought away from hooking the ball and losing your slice and this could be it\n",
            "BLEU score: 0.020828838183973034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sample_video_features = filtered_df['padded_numpy_array'][13]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model_transformers, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][13]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyBz5u3zV1In",
        "outputId": "08be5e80-bde0-403c-e72b-3993d3379bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: a lot of times it is very important to keep in mind that it is important to keep in mind that it is\n",
            "Ground Truth Translation: so the rules get a little bit convoluted but its important to remember first of all to stay on the strip\n",
            "BLEU score: 0.022023814946586635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sample_video_features = filtered_df['padded_numpy_array'][3]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model_transformers, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][3]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0lhfdkWWBbi",
        "outputId": "02abf510-1a9a-455e-da54-79cb97404766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: i have a computer that has a computer that has a computer that has a computer that has\n",
            "Ground Truth Translation: but what itll do is itll bring up a window on your computer that brings up the task manager\n",
            "BLEU score: 0.023914960914330066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sample_video_features = filtered_df['padded_numpy_array'][16]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model_transformers, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][16]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKyWPsDtWIO9",
        "outputId": "d77103ef-2fb1-442e-84c6-936b29fb9726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: i really want to make sure that you have a good workout on the back of the bike\n",
            "Ground Truth Translation: dont worry about your power dont worry about getting everything perfect just snap off a lot of punches\n",
            "BLEU score: 0.01284618972676772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sample_video_features = filtered_df['padded_numpy_array'][17]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model_transformers, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][17]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")\n"
      ],
      "metadata": {
        "id": "-aeVVt5-WUgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aff73c8e-ee50-4358-c8ea-0272ae2176fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: if youre going to be a little older you might be able to get a bigger car and you\n",
            "Ground Truth Translation: and doing this could be a little harder in smaller vehicle but it still could be done\n",
            "BLEU score: 0.057259987315337754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sample_video_features = filtered_df['padded_numpy_array'][9]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model_transformers, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][9]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkLCWFfExI8n",
        "outputId": "0ddeb470-8801-4307-ed73-6fc7c294c0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: i have a good chance to get a good swing and a good swing if you have a\n",
            "Ground Truth Translation: but a good player that has the strokes once they get the wheel chair down youre in trouble\n",
            "BLEU score: 0.025281168697394947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sample_video_features = filtered_df['padded_numpy_array'][18]\n",
        "\n",
        "# Predict the translation\n",
        "prediction = predict(model_transformers, tokenizer, sample_video_features)\n",
        "print(f\"Predicted Translation: {prediction}\")\n",
        "\n",
        "# Get the ground truth translation\n",
        "reference = filtered_df['translation'][18]\n",
        "print(f\"Ground Truth Translation: {reference}\")\n",
        "\n",
        "# Tokenize the reference and prediction\n",
        "reference_tokens = reference.split()\n",
        "prediction_tokens = prediction.split()  # Model prediction tokens\n",
        "\n",
        "# Apply BLEU score calculation with smoothing\n",
        "smoothing_function = SmoothingFunction().method1  # Smoothing to handle cases with zero n-gram matches\n",
        "bleu_score = sentence_bleu([reference_tokens], prediction_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "# Print BLEU score\n",
        "print(f\"BLEU score: {bleu_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6l-s0IixVOh",
        "outputId": "9a2ff366-8cd6-4a59-bdbb-fe87e59a853e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Translation: i need it\n",
            "Ground Truth Translation: this is a flamingo catch\n",
            "BLEU score: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def evaluate_split(model, tokenizer, df, split_name):\n",
        "    bleu_scores = []\n",
        "    predictions = []\n",
        "    smoothing = SmoothingFunction().method1\n",
        "\n",
        "    print(f\"\\nEvaluating {split_name} split...\")\n",
        "    for idx in tqdm(range(len(df))):\n",
        "        video_features = df['padded_numpy_array'].iloc[idx]\n",
        "        reference = df['translation'].iloc[idx]\n",
        "\n",
        "        try:\n",
        "            prediction = predict(model_transformers, tokenizer, video_features)\n",
        "            bleu = sentence_bleu([reference.split()], prediction.split(), smoothing_function=smoothing)\n",
        "\n",
        "            predictions.append({\n",
        "                'id': df['id'].iloc[idx],\n",
        "                'reference': reference,\n",
        "                'prediction': prediction,\n",
        "                'bleu': bleu\n",
        "            })\n",
        "            bleu_scores.append(bleu)\n",
        "        except Exception as e:\n",
        "            print(f\"Error at index {idx}: {e}\")\n",
        "            continue\n",
        "\n",
        "    results = pd.DataFrame(predictions)\n",
        "    results.to_csv(f'{split_name.lower()}_predictions.csv', index=False)\n",
        "\n",
        "    metrics = {\n",
        "        'mean_bleu': np.mean(bleu_scores),\n",
        "        'median_bleu': np.median(bleu_scores),\n",
        "        'std_bleu': np.std(bleu_scores),\n",
        "        'min_bleu': np.min(bleu_scores),\n",
        "        'max_bleu': np.max(bleu_scores)\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{split_name} Results:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    return metrics, results\n",
        "\n",
        "# Evaluate all splits\n",
        "train_metrics, train_results = evaluate_split(model_transformers, tokenizer, train_df, 'Train')\n",
        "val_metrics, val_results = evaluate_split(model_transformers, tokenizer, val_df, 'Validation')\n",
        "test_metrics, test_results = evaluate_split(model_transformers, tokenizer, test_df, 'Test')\n"
      ],
      "metadata": {
        "id": "twxE_6nBxjU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaaf04af-d765-4b41-9b6b-7198955a8a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Train split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20997/20997 [1:47:57<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Results:\n",
            "mean_bleu: 0.0334\n",
            "median_bleu: 0.0175\n",
            "std_bleu: 0.0560\n",
            "min_bleu: 0.0000\n",
            "max_bleu: 1.0000\n",
            "\n",
            "Evaluating Validation split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2625/2625 [13:36<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Results:\n",
            "mean_bleu: 0.0258\n",
            "median_bleu: 0.0141\n",
            "std_bleu: 0.0473\n",
            "min_bleu: 0.0000\n",
            "max_bleu: 0.8155\n",
            "\n",
            "Evaluating Test split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2625/2625 [13:35<00:00,  3.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Results:\n",
            "mean_bleu: 0.0255\n",
            "median_bleu: 0.0144\n",
            "std_bleu: 0.0418\n",
            "min_bleu: 0.0000\n",
            "max_bleu: 0.4483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}